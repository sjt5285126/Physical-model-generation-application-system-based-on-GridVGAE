题目 图生成网络用于生成不同条件下的Ising构型
摘  要
深度学习由于其分析复杂系统中基本特征的强大能力，因而在图像识别、语音处理和生物系统等领域有着广泛的应用。特别是在凝聚态物理学领域，深度学习已被证明能够准确近似复杂物理系统，展现其独特的能力。在过去的几年里，传统的神经网络在凝聚态物理学中的特征提取和模型生成方面都取得了良好的效果。然而，由于构型大小的限制，只能生成单一大小的构型，这限制了神经网络的通用性。传统的深度学习算法假设数据样本是相互独立的，但在真实的物理构型中，每个自旋节点都与构型中的其他节点和边相关联。
随着深度学习的发展，研究人员们开发了一种新型的用于非欧结构的神经网络算法--图神经网络(Graph Neural Network,GNN)。该算法结合传统的神经网络算法，通过使用图(Graph)这种数据结构来构建数据集用于提高构型的质量，并且可以在不同尺寸的构型之间快速切换，从而提高模型的通用性。同时，图神经网络算法不仅可以提高模型的性能，还可以减少计算量，从而可以缩短构型生成的时间。因此，图神经网络在凝聚态物理学中有着重要及广泛的应用前景。变分自编码器（Variational Auto Encoder，VAE）是基于变分推理的一种有监督式学习算法，其目标是将输入数据编码为潜在空间的变量，然后使用这些变量来重构输入数据。VAE 将变分推理引入到深度学习算法中，从而使其能够从训练数据中自动学习潜在空间的分布，并重构潜在变量的分布。VAE 的主要优势在于可以把高维的输入数据映射到潜在空间，从而可以更容易地检测隐藏的规律，发现更复杂的关系。
基于图神经网络与变分自编码器的特点，我们构建了一款基于格点的图变分自编码器(Grid Variational Graph Auto Encoder,VGAE)的Ising模型模拟器，其生成的Ising模型结果与传统蒙特卡洛方法模拟的数据非常接近。Ising模型是一种最基本的凝聚态物理模型，可以用于模拟物质的相变过程。该技术可以帮助研究人员更准确地预测物理性质，以及帮助设计出新材料和新模型，进而推动凝聚态物理理论的发展。图神经网络的另一个优势在于，它有助于探索复杂多元物理情况下的复杂结构和结果。此外，由于图神经网络可以在不同尺度上处理和表示信息，因此可以更好地结合有限元和拓扑分析，从而更好地提供复杂系统的数据分析和模拟结果。
最后，本文通过GridVGAE构建了物理模型生成应用系统，能够快速高效地生成Ising模型、XY模型等凝聚态物理模型。该系统为研究人员提供了一个快速、准确地生成物理模型的工具，可用于基础物理研究以及应用研究。
关键词：复杂系统模型;凝聚态物理;图神经网络;变分自编码;卷积神经网络

 
 
ABSTRACT
Deep learning has a wide range of applications in areas such as image recognition, speech processing, and biological systems due to its powerful ability to analyze fundamental features in complex systems. In particular, in the field of condensed matter physics, deep learning has been shown to accurately approximate complex physical systems, demonstrating its unique capabilities. In the past few years, traditional neural networks have achieved good results in both feature extraction and model generation in condensed matter physics. However, the limitation of the configuration size to generate only single-sized configurations has limited the generality of neural networks. Traditional deep learning algorithms assume that data samples are independent of each other, but in real physical configurations, each spin node is associated with other nodes and edges in the configuration.
 To address these issues, researchers have developed a novel non-Euclidean structured neural network algorithm, the Graph neural Network (GNN). The algorithm combines traditional neural network algorithms to improve the quality of the configurations by using a data structure such as a graph to build the data set, and can quickly switch between configurations of different sizes, thus improving the generality of the model. At the same time, the graph neural network algorithm can not only improve the performance of the model, but also reduce the computational effort, which can shorten the time of configuration generation. Therefore, graph neural networks have important and wide application prospects in condensed matter physics. Variational Auto Encoder (VAE) is a supervised learning algorithm based on variational inference, whose goal is to encode the input data as variables in the potential space and then use these variables to reconstruct the input data. vAE introduces variational inference into the deep learning algorithm, so that it can automatically learn the potential space distribution from the training data and reconstruct the potential variables. The main advantage of VAE is that it can map high-dimensional input data to the latent space, which makes it easier to detect hidden patterns and discover more complex relationships. 
Based on the characteristics of graph neural networks and variational self-encoders, we have constructed a Grid Variational Graph Auto Encoder (VGAE) based Ising model simulator, which generates Ising model results very close to those simulated by traditional Monte Carlo methods. The Ising model is one of the most fundamental condensed matter physics models that can be used to simulate phase transition processes in matter. This technique can help researchers to predict physical properties more accurately, as well as to design new materials and models, thus advancing the theory of condensed matter physics. Another advantage of graph neural networks is that they help explore complex structures and results in complex multivariate physical situations. In addition, since graph neural networks can process and represent information at different scales, they can better combine finite element and topological analysis, thus better providing data analysis and simulation results for complex systems.
 	Finally, this paper constructs a physical model generation application system through GridVGAE, which can generate condensed matter physical models such as Ising model and XY model quickly and efficiently. The system provides researchers with a tool to generate physical models quickly and accurately, and can be used for fundamental physics research as well as applied research.
Keywords: Ising model; Graph neural network; Variational autoencoder; Convolutional neural networks 
 
目  录
摘  要	I
ABSTRACT	III
第1章  绪论	1
1.1  研究背景及研究动机	1
1.2 研究现状	2
1.3  研究内容及研究目的	4
第2章  模型与方法介绍	6
2.1 Ising模型与图结构	6
2.1.1 Ising模型	6
2.1.2  图结构	6
2.2图神经网络	8
2.2.1 图卷积网络	8
2.2.2 图卷积推广	9
2.3 变分自编码器	10
2.4 生成数据集	11
2.4.1 蒙特卡罗方法	12
2.4.2 马尔科夫链	13
2.4.3 Metropolis算法	15
Wolff算法	17
2.5 数据集格式及所用技术	18
第3章  图变分自编码器模拟Ising模型	21
3.1 引言	21
3.2 数据预处理	21
3.3 格点图变分自编码器模型	22
3.3.1 编码器	22
3.3.2 解码器	23
3.3.3 损失函数	24
3.3.4 生成器	25
3.4 实验结果与分析	26
3.4.1 实验设计	26
3.4.1 实验结果	26
3.4.2  模型对比	28
3.4.3 敏感度分析	30
3.5 分析与讨论	31
第4章  基于GridVGAE的物理模型生成应用系统	33
4.1 绪论	33
4.1.1 项目背景	33
4.1.2 研发目的	33
4.1.3 主要工作	33
4.2 开发技术及环境分析	34
4.2.1 开发技术	34
4.2.2 硬件环境	35
4.2.3 MVC开发模式	35
4.3 任务概述	36
4.3.1 任务描述	36
4.3.2 条件与约束	36
4.3.3 用户特点	37
4.4 需求分析	37
4.4.1 功能需求	37
4.4.2 非功能需求	37
4.4.3 界面需求	38
4.5 可行性分析	38
4.5.1 技术可行性	38
4.5.2 经济可行性	39
4.5.3 法律可行性	39
4.6 软件设计	39
4.6.1 总述	39
4.6.2 总体设计	39
4.6.3 接口设计	40
4.6.4 模块设计	44
4.6.5 容灾设计	47
4.6.7 其他设计	48
 
 
第1章  绪论
1.1  研究背景及研究动机
随着复杂系统中自由度的增加，准确复制系统行为已经成为物理学界面临的一个日益严峻的挑战。Ising模型是一种最基本的凝聚态物理模型，它可以被用于模拟物质的相变过程，例如铁磁性材料的顺磁转铁磁。随着系统中自由度的增加，例如粒子数、自旋数、空间维度等的增加，Ising模型也可以被扩展为更复杂的系统。因此，Ising模型被广泛应用于描述和预测各种物理系统和生物系统的行为。然而，在面对高维复杂系统时，传统的物理学方法可能会遇到困难，因此我们需要寻求新的方法来解决这个问题。机器学习作为一种数据驱动的方法，可以通过学习大量的实验数据来构建模型，从而高效地逼近这些复杂系统。近年来，Ising模型和机器学习的结合成为了一个备受关注的研究方向，旨在探索更为高效和准确的模拟和预测复杂系统行为的方法。在众多机器学习方法中，深度学习在量子物理、凝聚态物理和高能物理等复杂物理现象的研究中显示出巨大潜力。
在过去的几年中，深度学习框架已被物理学科的各个分支所采用。从信息理论的角度来看，深度学习的成功部分归因于其反向传播训练方法和降维处理方法。在凝聚态物理中，深度学习对于复杂系统的低维描述，多尺寸模拟和降低计算量是非常有帮助的目前，深度学习在凝聚态物理领域的研究主要集中在两个方面：一是模拟（simulation）；二是优化（optimization）。在模拟方面，研究者们试图使用深度学习技术模拟各种物理系统，从而模拟现实世界中的动态过程。这些模拟使用的深度学习架构可以使用深度神经网络(DNN)、卷积神经网络(CNN)、递归神经网络(RNN)、变分自编码器(VAE)和生成对抗网络(GAN)等。优化方面，研究者们利用深度学习为传统物理模拟方法提供新的可优化或可控制变量，从而改进其精度和效率。深度学习新变量可以是神经网络参数或神经网络层，可以是离散或连续控制变量，也可以是策略参数或复杂从动策略。
然而，传统深度学习模型无法考虑到分子与分子之间的相互作用以及在训练过程中物理模型中分子之间的影响。同时，许多物理模型的微观结构是不规则的，生成模型的泛用性和准确性都较差。这就需要一个能够考虑非结构化数据的深度学习网络，并且不仅能计算节点与节点之间的相互作用，还能计算节点与边之间的关系。图卷积神经网络符合这一要求，图神经网络处理非结构化数据的出色能力使其在物理、生物和化学领域有着极大作用。大多数复杂系统物理模型本质上是一种图结构，而传统的卷积神经网络将物理模型理解为图像网格结构，这么做的结果不仅导致精度降低而且无法处理很多复杂的物理系统。与传统卷积网络相比，图卷积网络可以处理任意数据类型与任意数据结构，并且可以学习任意长度的图形特征，同时图卷积网络可以根据每个节点的特征，构建其与其他节点的链接，处理不规则图结构，这为我们处理类似于六方晶格、不规则晶格提供了有效工具，而卷积神经网络只能处理规则图结构类似于单尺寸Ising构型。图卷积网络可以利用多种图属性计算器所有节点的特征，例如用来处理多尺寸Ising构型、双层IsingXY耦合模型等，而CNN仅能利用一种属性分析图像特征，导致模型的特性丢失。
综上所述，传统的卷积神经网络在对复杂系统的模拟方面仍有很多不适用的场合，即便能处理一些模型也无法做到精确性与泛用性。因此，利用图卷积神经网络的特性来补充传统卷积神经网络的不足，以提高模拟复杂系统的精确性和泛用性，将深度学习更加深入的应用到凝聚态物理领域并逐渐投产到企业实际应用领域，是当前的研究目标之一。
1.2 研究现状
Ising模型作为一种经典的统计物理模型，在机器学习领域也引起了广泛的关注和研究。目前，机器学习在Ising模型研究中主要涉及四个方面：参数估计、模型选择、相变预测和采样。
首先是参数估计。在实际应用中，我们通常需要从实验数据中推断出模型的参数。在Ising模型中，参数估计通常是一个最大似然或最大后验估计问题，需要解决高维空间中的优化问题。近年来，机器学习方法在Ising模型参数估计中得到了广泛应用。其中，基于神经网络的方法是一种非常有效的方法，通过构造合适的神经网络结构来近似Ising模型的概率分布，进而进行参数估计。同时，一些基于梯度下降、蒙特卡罗方法、贝叶斯推断等的机器学习方法也在Ising模型参数估计中得到了广泛的应用。例如我们采用非限制玻尔兹曼机、变分自编码器和生成对抗网络通过模型训练来拟合Ising模型的概率分布，从而得到Ising模型的参数。在这方面，兰切斯科·德安杰罗和卢卡斯·伯彻在PHYSICAL REVIEW RESEARCH发表的Learning the Ising model with generative neural networks就将非限制玻尔兹曼机与变分自编码器应用在Ising模型的参数模拟上，并且通过概率分布生成了物理特征正确的Ising模型。
其次是模型选择。在实际应用中，我们通常需要选择最适合实验数据的Ising模型，这涉及到模型比较和选择问题。在机器学习领域中，模型比较和选择问题一直是一个热门的研究方向。针对Ising模型，一些基于贝叶斯推断、信息准则、交叉验证等的机器学习方法被广泛应用于模型选择问题。这些方法可以有效地评估不同模型的拟合效果，从而选择最合适的模型。还有一种方法是通过Ising模型的物理特性，将通过神经网络生成的Ising构型进行物理特性的计算，得出不同神经网络生成Ising模型的拟合效果，目前该方法在主流的机器学习应用在Ising模型上的研究得到了广泛应用。
 再然后是相变预测。相变是指物质从一种相态转变为另一种相态的过程，这种转变在温度、压强等外部条件一定范围内发生。相变可以是物理性质的巨大变化，例如密度、热容、磁化等，这些物理性质的变化在某一温度或压强下具有突变特征，称为相变点。相变可以分为两种类型：一种是一阶相变，即相变点处物质的自由能不连续，在温度或压强发生变化时，物质在相变点附近会出现凝聚和融化的现象；另一种是二阶相变，即相变点处物质的自由能连续但其导数不连续，在相变点附近，物质的物理性质呈现出连续性的变化，例如铁磁性材料的顺磁转铁磁。相变是物质在不同相态之间转变的重要现象，对于理解物质的物理性质和研究物质的行为具有重要意义。相变的研究在材料科学、物理学、化学、地球科学等多个领域都有着广泛的应用。Ising模型的相变对于超导材料的获取与应用有着至关重要的作用。"Discovering phase transitions  with unsupervised learning"（Carrasquilla和Melko，2017）这篇论文是关于无监督学习如何用于识别物理系统中的相和相变1。作者使用了主成分分析和聚类分析等无监督学习技术，从原始自旋构型中提取出相关的低维表示，并在特征空间中使用聚类分析来识别不同的相。这种方法成功地发现了物理概念，例如序参量和结构因子，作为相变的指标。作者还讨论了使用无监督学习技术发现更复杂的相和相变的未来前景。"Machine learning phases of matter"（Juan Carrasquilla, Roger G. Melko，2017）这篇论文提出了一种基于机器学习技术的相变分类方法，主要工作是将Ising模型的不同相转化为图像，并应用卷积神经网络（CNN）进行分类。该方法可以对不同相进行准确分类，并可以推广到其他物理模型中。
最后是采样问题。在实际应用中，我们通常需要从Ising模型中生成大量的样本，以进行模拟和实验。由于Ising模型中的变量数量通常较大，传统的蒙特卡罗方法可能会面临高计算成本和效率低下的问题。近年来，基于机器学习的采样方法得到了广泛的应用，这些方法可以利用神经网络等机器学习技术来加速采样过程，大大提高采样效率和准确性。而在机器学习中，有一种名为生成网络的神经网络模型，这种网络模型能够根据训练得到的概率分布生成出全新的图像，这一网络模型很快便应用到Ising模型中。"Learning to Generate Configurations of Statistical Models" (ICML 2016) 该论文提出了一种基于生成对抗网络（GANs）的方法来生成Ising模型的构型。其中，判别器的输入为一组构型和温度值，输出为对应构型的真实度量值（即自由能）。生成器的输入为噪声向量和温度值，输出为对应的Ising构型。通过对生成器和判别器的对抗训练，可以得到一个能够生成高质量Ising构型的生成器。该方法在复杂度较高的二维和三维Ising模型上取得了较好的效果。
在上述问题中，卷积网络采用的都是将Ising模型转变成图像网格形式再进行训练，这就导致了Ising模型的特性并没有被完全利用，在图神经网络问世前，我们认为这种方式是可行的，但在图神经网络问世后，也将它用来对Ising模型的相变行为进行研究。
一种常见的应用是通过构建Ising模型中的相邻关系图（也称为Ising网络），将图神经网络应用于Ising模型的相变分类问题。在这个问题中，目标是将Ising模型的状态分类为“相变”或“非相变”。研究者通常会在相变温度附近进行大量的模拟，产生大量的训练数据，然后使用这些数据训练一个图神经网络，将它应用于新的状态，以预测其相变行为。在这方面的研究有很多，Emma Slade等人（2021）在他们的论文《GNisi: A graph network for reconstructing Ising models from multivariate binarized data》中，提出了一种新的方法，使用图神经网络来重构Ising模型。作者使用了一种基于图卷积神经网络（GCN）的方法，该方法可以在不需要任何先验知识的情况下重构Ising模型。作者还展示了如何使用这种方法来重构具有不同相变行为的Ising模型。
图卷积网络在提取物理特征信息方面也已经非常强大，V. Bapst等人发表的《Unveiling the predictive power of static structure in glassy systems》这篇文章是关于用图神经网络来研究玻璃的性质和动力学的。玻璃是一种无定形的材料，它在升温时会从硬而脆的玻璃态过渡到粘性或橡胶状的液态，这个过程叫做玻璃相变。玻璃相变是一个复杂的现象，它涉及到分子层面的结构和运动的变化，对于许多固体材料的可见特征有着重要的影响。文章介绍了作者开发了一种新颖的图神经网络模型，能够从原子轨迹中学习玻璃分子的动力学特征，并预测它们在不同温度下的行为。文章还展示了这种模型在不同类型的玻璃（如硅酸盐、聚合物等）上的应用，以及它在理解玻璃转变、堵塞转变等现象中的潜力。这表明了图卷积网络已经能够解决对人类来说非常复杂和困难的问题。
综上所述，图卷积网络在物理领域的应用前景非常广泛，它具有普通神经网络不具备的精确特征提取以及泛用性。Ising模型的研究也是复杂系统研究的重要课题，我们认为使用嵌入图卷积的图变分自编码器来生成Ising构型是一个十分重要且可行的工作。此外，随着深度学习的不断发展和图神经网络技术的不断改进，我们相信该方法在未来将会得到更加广发的应用。
1.3  研究目的及内容
本研究的主要目的是提出一种新颖的图变分自编码器模型(GridVGAE)来模拟Ising模型，并基于该模型开发一个基于web的应用系统，以帮助研究人员更准确地预测物理性质，推动凝聚态物理理论的发展。同时，本研究还旨在验证GridVGAE模型在生成不同条件下的Ising构型方面的有效性和优越性，并展示其在捕捉Ising模型中的关键特征方面的优越性。
本研究分为两部分。第一部分提出了一种新颖的图变分自编码器模型(GridVGAE)，用于模拟Ising模型，能够生成不同条件下的Ising构型。本文提出的模型将重点放在了节点的状态预测上，而不是边的预测，这也符合Ising模型中节点只有正负两个状态的特点。本文采用了全连接神经网络来实现解码器，这样可以更好地对每一个节点进行特征提取，而不是聚合邻居信息 。本文采取了带边权中的图卷积网络，更符合物理模型的现实特征，以求提高模型的准确性。
为了验证模型的准确性，我们将其与传统物理生成方法，传统神经网络生成模型以及使用不同图卷积网络的图变分自编码器生成模型做对比。同时对模型超参数进行敏感度分析，例如KL散度权重和卷积操作数量和类型等，以研究这些参数对模型性能的影响。
第二部分旨在构建一个基于web的应用系统，其主要目标是辅助研究物质特性或社会性质。该系统应用领域主要涉及物理学和经济学等领域，利用图神经网络和变分自编码器的深度学习算法，能够生成不同模型。同时也研究了使用GridVGAE来生成物理模型在企业实践中的有效性，在未来可以推广到更多物理模型上。
1.4 论文结构
第一章,介绍了本篇论文的内容,目的和结构,并陈述了深度学习研究凝聚态物理模型生成问题的背景、意义以及研究动机。
第二章，详细描述了研究所用到的模型结构、数据集的生成与处理，以及在研究过程中使用的工具和技术。
第三章，展示了研究成果，包括数据分析、模型建立、模型结果验证等。实验把用模型生成的Ising构型和使用传统方法生成的Ising构型的物理特性进行对比，同时将其与传统卷积网络和普通的图神经网络生成的构型精准度进行了比对。
第四章，本篇将论文研究结果--图生成网络来生成不同条件下的Ising构型制作为一款企业项目。它利用图神经网络来模拟Ising构型，形成可视化仿真系统，通过使用不同的图神经网络模型、优化模型参数以更加有效地改善企业的效率和成果
第五章，综合上述研究情况，总结本研究的发现和收获，指出本研究的局限性，并给出建设性建议和未来研究方向。
 
第2章  模型与方法介绍	
2.1 Ising模型与图结构
2.1.1 Ising模型
Ising模型是一种统计物理模型，用来表示一组相互交互的二维或三维磁性点的状态。每一个点都有一个磁矩，它们之间的交互力使它们保持相同（或者相反）的磁矩。该模型可以用来研究多种不同的物理系统，包括金属的磁化，线性玻璃的熔融，以及生物体的行为。该模型假设磁矩本身可以被调整来模拟实际系统中发生的许多状态（如磁极性）。Ising模型可以用来描述实际系统的行为，以及它们可能的热力学行为。在统计物理学中，Ising模型被描述为在某些晶格中具有耦合相互作用的二元自旋的集合。考虑到N个自旋s=s_i可以取值±1，其中索引i标记自旋s_i的位置，Ising系统的标准哈密顿量仅包括最近邻相互作用，每个自旋方向可以是“向上”（+1）或“向下”（-1）如图2.1所示，尽管广义模型可能包括长程相互作用和更多的自旋选择性方向。标准哈密顿量为：
	H= -J∑_neighbors▒〖S_i*S_j 〗	(1)



图2.1 Ising模型
Figure 2.1 Ising model

2.1.2  图结构
图是代表数据点之间关系的节点和边的集合。节点代表单个数据点，而边代表节点之间的关系。图可以用来模拟各种各样的系统，如社会网络、交通网络和计算机网络。图也可以用来表示数据库中实体之间的关系，或者用来表示人工智能中的问题域。图是由多个元素组成的，如节点、边和标签。节点代表单个数据点，而边代表节点之间的关系。标签可以用来提供关于节点和边的额外信息。图可以是定向的（即边有一个方向）或无定向的（即边没有方向）。图形也可以是加权的（即边上有一个与之相关的数值）或无权的（即边上没有与之相关的数值）。
 

图2-2 带权值的图结构
Figure 2-2 Graph structure with weights
图结构中相关符号的描述和定义如下：
定义一 图：一个图由节点和连接节点的边构成，通常用G=(V,E)表示，其中V={v_1,v_2,...,v_n}表示节点集合，E={e_1,e_2,...,e_n}表示边集合，边也可以用(v_1,v_2)的方式来表示。节点也被称为交点，边也被称为弧。通常，图可以表示为一个五元组: G(V,E,A,X,D)，其中邻接矩阵A描述节点之间的连接关系，节点特征矩阵X描述节点的属性，度矩阵D描述每个节点的度数。
定义二 邻接矩阵:图的临界矩阵指用于表示图中节点的连接情况的矩阵.该矩阵可以是二值的,也可以是带权的.对于有N个节点的无向图来说,邻接矩阵是一个N*N的实对称矩阵.
定义三 度矩阵:节点的度表示与该节点相连的边的数量.图的度矩阵即用于描述图中每个节点的度的矩阵.度矩阵是一个对角矩阵,对于无向图来说,一般只使用入度矩阵或者出度矩阵.
定义四 拉普拉斯矩阵：组合拉普拉斯矩阵,又称标准拉普拉斯矩阵,由对角矩阵和邻接矩阵组合而成
	L=D-A	(2)
该矩阵只在中心节点和一阶相连的节点上有非零元素,其余之处均为零.拉普拉斯矩阵也是图的一种表现形式.
定义五 归一化拉普拉斯矩阵
	L^sym=I-D^(-1/2) AD^(-1/2)	(3)
其元素值为：
	L_(i,j)^sym={█(1@-1/√(deg⁡(v_i )  deg⁡(v_j ) )@0),█(i=j,且 deg⁡(v_i )≠0@i≠j,并且v_i 与v_j 相连\ )¦其他┤	(4)
其中deg⁡(v)表示为节点v的度
2.2图神经网络
2.2.1 图卷积网络
图卷积是一种在图结构数据上进行卷积运算的方法，它是由传统的卷积神经网络发展而来的。与传统的卷积操作不同的是，图卷积是在节点的邻居结构上进行的。具体来说，图卷积将每个节点的特征向量与其邻居节点的特征向量进行聚合，并根据聚合后的结果进行特征更新，从而实现了在图结构上的信息传递和特征提取，如图2.3所示。


图2.3 图卷积聚合邻居节点信息
Figure 2.3 Graph convolution aggregates neighbor node information
在了解图卷积之前，我们先要对卷积操作有一个基本的概念。卷积网络最开始应用在图像上，我们将图像上的像素点作为特征来进行卷积操作提取特征。用随机的共享的卷积和得到像素点的加权和从而提取到某种特定的特征，然后用反向传播来优化卷积核参数就可以自动的提取特征，是卷积神经网络提取特征的基石。可以这么认为,卷积操作相当于将周围的像素点信息聚合到卷积核中央像素点上，提取出该部分的特征。
(a)
(b)

图2.4 普通卷积操作与卷积网络流程
Figure 2.4 Ordinary convolution operation and convolutional network process
因此，我们希望在图域中使用卷积来使用图特征提取的通用范式，如图2.5所示，红色的节点v_i聚集了来自黄色的相邻节点v_j的特征。(a) l=1(b)l=2。小正方形表示节点的特征向量。当我们想要获得节点的特征表示时，我们可以聚合相邻节点的信息，这可以通过这种方式理解，图中的每个节点都在一直改变其状态，直到最终平衡，因为相邻节点内核的较远点的影响，邻居越近，影响越大。
 

图2.5 多层图卷积建立长程联系
Figure 2.5 Multi-layer graph convolution establishes long-range connections
2.2.2 图卷积推广
对于图卷积网络来说，我们想要学习到它对于每个节点的特征表示，任意的图卷积都可以写成这样的一个非线性函数：
	H^(l+1)=f(H^l,A)	(5)
H^0=X为第一层的输入,l代表神经网络的层数,A代表邻接矩阵.
传统的图卷积网络做法就是将邻居节点的信息加入到本节点当中:
	f(H^l,A)=σ(AH^l W^l)	(6)
W_l  代表第l层的参数矩阵,σ代表激活函数. 根据矩阵乘法可以看出上式中的每个节点都结合了相邻节点的信息,但由于仅仅使用了邻接矩阵,邻接矩阵对角线为0,无法体现节点自身的信息,所以我们使用拉普拉斯矩阵来代替邻接矩阵
	f(H^l,A)=σ(LH^l W^L)	(7)
上式中引入了拉普拉斯矩阵,从而解决了没有考虑自身节点信息自传递的问题,但是由于没有被规范化,我们将拉普拉斯矩阵规则化得到图卷积
	f(H^l,A)=σ(L^sym H^l W^l)	(8)
上面讲述的都是以矩阵形式计算，我们也可以从单个节点角度来观察公式，对于第l+1层的节点特征h^(l+1),对于他的邻接结点j∈N,N是结点i的所用邻居结点的集合,所以图神经网络的更新公式同样可以描写为
	h_i^(l+1)=f(h_i^l )=σ(h_i^l  ⋅W_1^(l+1)+∑_j▒〖h_j^l⋅W_2^(l+1))〗	(9)
2.3 变分自编码器
变分自编码器是一种变分推理的生成模型,由编码器和解码器两部分网络组成,它是包含隐变量的一种模型.在变分自编码器当中,我们基于这样的假设: 我们的样本x是某些隐变量z(latent variable)通过某种映射产生出的,而z也不是一个固定值,而是服从一个分布:z∼P_θ (z),则x∼p_θ (x∣z),这里的P是由参数θ决定的分布族,而θ就是我们需要找到的真实分布.所以我们最根本的目标就是确定z和θ的值,这样就能够得到样本x.为了推断p_θ (x∣z),我们需要最大化边际对数似然log(p_θ (x))我们可以重写该式：
	█(log⁡(p_θ (x))&=log∫p_θ (x│z)dz@&=log∫▒(p_θ (x│z)p(z) q_ϕ (z│x))/(q_ϕ (z│x) )  dz@&≥E_(z~q_ϕ (z│x) ) [log⁡〖p_θ (x│z)〗 ]-D_KL (q_ϕ (z│x)│p(z) )@&≔ε(x,θ,ϕ) )	(10)
我们在第四步应用了Jensen不等式.在第二步中对潜在变量z的积分通常是棘手的,因此我们引入了带有参数集ϕ的近似后验分布q_ϕ (z∣x)并使用变分推理原理来获得边缘对数似然的易处理界限,即证据下界(ELBO)[22].我们使用p(z)=N(1,0)作为潜在变量先验.ELBO是对数似然的易处理下界,因此可以最大化推断p_ϕ (x∣z).Ez∼qϕ(z∣x)[log(pϕ(x∣z))]可以理解为重构误差,因为最大化它会使解码器的输出类似于编码器的输入,DKL\(qϕ(z∣x)∣p(z)]是KL散度,一种衡量两个分布相似性的数值,它可以确保潜在表示是高斯的,使得具有相似特征的数据点具有相似的高斯表示。
我们已经概述了潜在变量模型背后的一般思想，但我们仍然需要指定近似（变分）后验q_ϕ (z∣x)和模型似然log_ϕ⁡〖(p(x∣z))〗.近似后验的常见选择是分解高斯分布
	q_ϕ (z│x)=∏_(j=1)^d▒〖N(z_j ┤| μ_j,σ_j^2)〗	(11)
其中μ和σ表示模型的均值和标准差.
总而言之,VAE是一种基于提取出p(z∣x)的潜在高斯表示q_ϕ (z∣x)的均值与方差的编码器网络.VAE中的解码器,它使用高斯q_ϕ (z∣x)的样本作为输入,根据分布p_θ (x∣z)生成新样本.我们通过使用反向传播最大化ELBO来计算所有的参数,但是高斯分布是随机的,不可微的.因此需要在编码器的输出和解码器的输入之间建立一个确定性和可微分的映射.我们需要将随机变量z表示为另一个辅助随机变量ϵ的可微可逆变化g(即z=g(μ,σ,ϵ)).我们采用重参化技巧[22],使g(μ,σ,ϵ)=μ+σ⊙ϵ即
	z=μ+σ⊙ϵ	(12)
其中ϵ~N(0,1)和⊙是元素乘积
 

图2.6 变分自编码器基本架构
Figure 2.6 Basic architecture of variational autoencoder
2.4 生成数据集
Ising模型是描述磁性物质相互作用的重要模型，常常用于描述铁磁性和铁磁相变现象等。Ising模型中的构型是指在一定温度下，物质中所有粒子的磁矩方向组成的空间分布情况。生成符合Ising模型分布的构型，对于理论研究和实际应用都具有重要意义。
但是，直接从Ising模型中采样构型是一件非常困难的事情。这是因为Ising模型的分布往往非常复杂，且在实际应用中通常无法求解其精确分布。因此，我们需要寻找一种可行的方法来生成符合Ising模型分布的构型。
马尔科夫链蒙特卡罗（MCMC）方法是一种基于马尔可夫链的随机模拟方法，可以生成符合特定分布的样本。因此，我们可以利用MCMC方法来生成符合Ising模型分布的构型。具体来说，可以通过构建一个基于Metropolis-Hastings算法或者wollf算法的MCMC马尔科夫链，从任意初始构型出发，不断进行状态转移，最终得到符合Ising模型分布的构型样本集合。
利用MCMC方法生成Ising构型具有很多优点，例如可以避免手动构造构型、适用于各种不同类型的Ising模型、适用于各种不同类型的构型等。同时，通过生成大量的符合Ising模型分布的构型，我们可以进一步研究和探索Ising模型的性质和规律，为相关领域的研究提供重要的数据支持。
在该节中将会介绍蒙特卡罗方法，马尔科夫链，以及基于他们实现的生成算法用来保证我们的研究数据准确无误。
2.4.1 蒙特卡罗方法
蒙特卡罗方法是一类基于随机采样的数值计算方法，通常用于估计复杂的数学问题的解。这些问题可能是高维、非线性、难以求解或难以分析的。蒙特卡罗方法的基本思想是通过对问题的定义域进行随机采样，并对采样点进行函数计算，然后基于这些计算结果来估计问题的解。这种方法不需要对问题进行复杂的数学分析，而只需要进行简单的模拟计算，因此非常适用于处理复杂的数学问题。
具体来说，蒙特卡罗方法的基本流程包括以下几个步骤：
(1) 定义问题的定义域和要求解的函数；
(2) 在定义域上进行随机采样，并对采样点进行函数计算；
(3) 根据采样点的计算结果，估计问题的解；
(4) 通过增加采样点的数量来提高估计的准确性。
蒙特卡罗方法的核心是随机采样。采样可以通过各种方式进行，例如均匀采样、重要性采样、马尔科夫链蒙特卡罗等。在我们的数据集生成中，使用的为马尔可夫链蒙特卡罗方法。采样点的数量越多，蒙特卡罗方法得到的估计值越准确，但同时也会增加计算时间和计算资源的需求。例如我们在面积为S_0的盘子中有一块不规则的区域。我们向盘子中均匀撒M个点，其中有N个点落在不规则区域内，据此我们可以估计出不规则区域的面积：
	S≈S_0×N/M	(13)


图2.7 利用蒙特卡罗方法计算圆的面积
Figure 2.7 calculates the area of the circle using the Monte Carlo method

在这个例子中，整体是盘子内的无限多个点，样本是随机抽取的 M个点，待测的统计学量是不规则区域中的点占整体的比例。在M趋于无穷大时，约等号变成等号：
	S=S_0  ×lim┬(M→∞)⁡〖N/M〗	(14)
2.4.2 马尔科夫链
蒙特卡罗方法需要一个服从目标分布的样本集合，但是在大多数情况下，我们并不知道如何直接从目标分布中采样，对Ising模型的采样就属于这种情况。这时，我们需要一种工具，能够在一定条件下经过足够多次的状态转移逐渐接近目标分布，这便是马尔科夫链。这种逐渐接近的过程被称为马尔科夫链的收敛。
马尔科夫链(Markvo chain)是一种描述随机过程的数学模型。它的本质是一个序列，其中每个状态只依赖于前一个状态，而不依赖于更早的状态。因此，马尔科夫链可以看作是一种“记忆长度有限”的随机过程。
具体来说，如果一个随机过程在时刻t的状态为x_t，那么在下一个时刻t+1，该随机过程的状态x_(t+1)满足一下条件：x_(t+1)的概率分布只与x_t有关，而与之前的状态x_1,…,x_(t-1)无关。


图2.8 马尔科夫链过程
Figure 2.8 Markov chain process
马尔科夫链通常由三部分构成：状态空间(state space)：表示随机过程可能处于的所有状态的集合；转移概率(transition probability):表示从一个状态转移到另一个状态的概率。具体来说，如果状态空间为S,则转移概率可以表示为矩阵P={p_ij}，其中p_ij表示从状态i转移到状态j的概率；初始状态概率(initial state probability):表示随机过程开始时，处于每个可能状态的概率分布。
马尔科夫链的性质包括：
	马尔科夫性：马尔科夫链具有无记忆性，即在给定当前状态下，未来状态的概率分布只与当前状态有关，而与过去状态无关。
	长期行为：随着时间的推移，马尔科夫链的状态将会发生变化，最终可能会收敛到一个稳态分布。这个稳态分布可以通过计算马尔科夫链的转移概率矩阵的特征向量得到。在稳态分布下，马尔科夫链的状态分布不再随时间变化而发生变化。
	细致平衡条件：对于任意两个状态 i 和 j，在马尔科夫链的稳态分布下，从状态 i转移到状态j的概率与从状态i转移到状态j的概率相等。
马尔科夫链在实际问题中有广泛的应用。例如，在自然语言处理中，可以将一个文本看作一个马尔科夫链，每个状态代表一个单词或一个句子，转移概率矩阵描述了单词或句子之间的转移概率。在图像处理中，可以将像素看作状态，转移概率矩阵描述了像素之间的相似度和空间关系。在机器学习中，马尔科夫链可以用于生成模拟数据集和模型训练等。
为了实现马尔科夫链，需要确定状态空间和转移概率矩阵，并计算其平稳分布。通常，状态空间可以从实际问题中得出，而转移概率矩阵和平稳分布需要根据实际问题进行计算。在实际应用中，方法包括Metropolis算法、wollf算法、Gibbs采样等。
然而，马尔科夫链也存在一些局限性，例如长期依赖问题、收敛速度慢等。为了克服这些问题，研究者们提出了一些改进和扩展的方法，例如隐马尔可夫模型、条件随机场等。未来，马尔科夫链在自然语言处理、图像处理、机器学习等领域的应用前景依然广阔，研究者们也将不断探索更加高效、准确的方法来解决现实问题。
2.4.3 Metropolis算法
Metropolis算法是一种马尔可夫链蒙特卡罗（MCMC）方法，用于生成符合指定概率分布的随机样本。Metropolis算法最初是由Nicholas Metropolis等人在1953年发明的，其主要思想是基于接受-拒绝采样（accept-reject sampling）方法和马尔可夫链的思想，通过构造一个满足细致平衡条件的转移矩阵来生成符合指定概率分布的随机样本。具体来说，Metropolis算法的步骤如下：
算法1
	初始化：给定初始状态x_0,设定转移矩阵Q(x,y)
	 for t = 1 to N do  //重复迭代N次 
		 	y ~ Q(x_i,y) // 从状态x_i开始，根据状态转移矩阵Q(x_i,y)生成一个候选状态y
			α(x_i,y)←min⁡{1,p(y)Q(y,x_i )/p(x_i )Q(x_i,y) } //计算接受概率
			u∼U(0,1)
			if u≤α(x_i,y) then 
				x_(i+1)=y // 接受y
			else	
				x_(i+1)=x_i //保持不变 
			end if	
		end for
	Return Draw histogram of {x_0,x_1,…,x_N} // 输出抽样序列
其中，接受概率α(x,y)的计算方式为：
	α(x,y)= min⁡{1,p(y)Q(y,x)/p(x)Q(x,y) } 	(15)
p(x)表示指定的概率分布，Q(x,y)表示转移矩阵的元素，即从状态x转移到状态y的概率。


图2.9 Metropolis算法示意图，其中i,j为要翻转的状态,α(i,j)为接受率,q(i,j)为翻转概率
Figure 2.9 Schematic diagram of Metropolis algorithm, where i,j is the state to be flipped,α(i,j) is the acceptance rate, and q(i,j) is the flipping probability
Metropolis算法的优点在于可以处理复杂的概率分布，同时能够在高维空间中生成样本。它的缺点是需要调整转移矩阵的元素，以使得接受率尽可能高，这可能需要一定的经验和计算成本。此外，在接受率较低的情况下，样本的生成速度会变慢。
我们得到Metropolis的接受概率的方式是通过构建它的细致平衡原则，如果Metropolis算法达到稳态，也就是说状态转移矩它的任意两个状态是相通的，以此基础来推导：当一个系统达到平衡态时，我们用P(x)表示系统在平衡态下处于x态,使用W(x→y)表示系统从x态转变为y态的概率。为了满足细致平衡原则，系统从状态x到状态y的概率应该与从状态y到状态x的概率相同：
	W(x→y)P(x)=W(y→x)P(y)	(16)
我们将转移概率W(x→y)分解为两个概率的乘积，即从状态x产生一个提议q(x→y)的概率和接受该提议α(x→y)的概率：
	W(x→y)=q(x→y)α(x→y)	(17)
则细致平衡原则W(x→y)P(x)=W(y→x)P(y)可以改写成：
	P(x)q(x→y)α(x→y)=P(y)q(y→x)α(y→x)	(18)
由于一步只能翻转一个分子，所以只有在x,y的差别不大于一个分子的时候，q(x→y)才不为0，由于选取分子是随机的，所以：
	q(x→y)=1/N(N为分子数)	(19)
所以由Eq.(18)可得：
	α(y→x)/α(x→y) =W(x→y)P(x)/W(y→x)p(y) 	(20)
由P(x)=e^(-βE)可知，
	α(y→x)/α(x→y) =e^(-β〖(E〗_x-E_y))	(21)
由Eq.(21)我们可以得到Metropolis接受准则，这就成为算法计算能否进行状态转移的关键,也就是我们所说的接受概率：
	α(∆E)={█(1@e^(-β∆E) ) (∆E<0)¦(∆E>0)┤	(22)
Wolff算法
Metropolis算法的局限性在于一次翻转的分子太少，wolff算法是一种集团翻转的方式。它的具体步骤是：
 
算法2
	初始化：在系统中随机抽取一个分子x作为种子
	 init stack,cluster
	 stack.push(x) // 将x放入栈中
	 cluster.push(x) // 将x放入集簇
	 while stack no empty: //只要栈不为空
		 	y = stack.pop()
			neighs = y.neighbor()
			for neigh in neighs:
				u ~ U(0,1)
				if u≤padd(1-e^(-2βJ)) then:
					cluster.push(neigh)
					stack.push(neigh)
				end if
			end for	
		filp cluster
	Return configuration
无论是Metropolis算法还是wolff算法,都是MCMC方法,所以wolff算法也需要满足细致平衡原则。但与Metropolis算法不同的是选取概率Q(A→B)不再是1/N,不过在已经得到的细致平衡公式中我们更关心的是(Q(A→B))/(Q(B→A))。
 
图2.10 wolff算法示意图
Figure 2.10 Schematic diagram of wolff algorithm
一个cluster的停止，取决于与这个cluster相邻的同向分子的数目。看起来就像是cluster与这些同向的分子“断开了连接”，故称之为“断键”。
如图*所示，如果A->mid需要断m个键,B->mid需要断n个键那么:
	(Q(A→B))/(Q(B→A))=〖(1-P_add)〗^m/〖(1-P_add)〗^n  〖"=" (1-" " P_add ")" 〗^(m-n)	(23)
由细致平衡公式𝑃(𝐴)𝑃(𝐴→𝐵)=𝑃(𝐵)𝑃(𝐵→𝐴)可得:
	P(A→B)/(P(B→A))=Q(A→B)α(A→B)/(Q(B→A)α(B→A))=〖(1-P_add)〗^(m-n)  (α(A→B))/α(B→A) =e^(-β(E_B-E_A))	(24)
又因为E_B-E_A=2J(m-n)于是我们得到了：
	(1-Padd)^(m-n)  A_(u→v)/A_(v→u) =e^(-2βJ(m-n) )  	(25)
最后简化得到
	A_(u→v)/A_(v→u) =e^2βJ (1-Padd)^(n-m)	(26)
由此可知当Padd=1-e^(-2βJ)时：
	A_(u→v)/A_((v→u) ) =1	(27)
由此可知接受率为1,只要构造出这个cluster,我们就一定翻转他.
2.5 数据集格式及所用技术
PYG(PyTorch Geometric)是一个用于处理图数据的PyTorch库，旨在提供一组易于使用的高效的工具和模型，支持各种图学习任务，例如节点分类、图分类、链接预测和图生成。PYG具有高度的灵活性，可以支持多种图类型（有向图、无向图、多重图等）和数据格式（边表、邻接表等），并具有自定义图卷积层、节点嵌入等模块。PYG还提供了一个图形数据集处理器，可以快速加载并处理许多流行的图形数据集。通过PYG，用户可以方便地使用PyTorch的GPU加速和自动微分功能，快速实现并调试各种图神经网络模型。
本文将利用PyG的数据结构来对Ising模型进行图结构处理。图结构对节点之间的成对关系进行建模。下面将介绍PyG库的图结构包含哪些内容：
节点(x):是一组带形状的节点特征矩阵，形状为[num_nodes,num_node_features]。
边索引(edge_index):具有形状和类型的COO格式 的图连接[2,num_edges] torch.long
边属性(edge_attr):带形状的边缘特征矩阵[num_edges,num_edge_features]
图标签(y):要训练的目标（可以是节点也可以是图）的标签[num_nodes,*],[1,*]
我们对Ising构型采取将自旋点加入到x中，对相邻自旋点构建edge_index，同时将 edge_attr设置为自旋之间的能量。
同时我们将使用PyG内置的图神经网络算法以及配套的算法实现基础来实现我们的神经网络模型。PyG构建图神经网络采用的是消息传递网络（Message Passing Neural Network,MPNN）,MPNN是从现有模型中抽象出来的，可以适用于绝大部分图神经网络的构建。
以图2.11为例，假设我们要计算k时刻红色节点的表示，从消息传递的角度来看，会经历以下步骤：1）首先从邻居获取信息：计算红色节点周围的四个邻居节点的消息总和。2）对获得的信息加以利用：将获得的消息与 (k-1) 时刻红色节点本身的表示组合起来，计算得到 k时刻的红色节点表示。


图2.11 消息传递网络计算方式
Figure 2.11 Message passing network calculation
在理解了消息传递过程之后，我们正式介绍形式化的消息传递过程。MPNN共包含两个阶段：消息传递阶段和读出阶段。
(1)消息传递阶段 ：共运行T个时间步，并包含以下两个子函数：Aggregation Function：也称消息函数，作用是聚合邻居节点的特征，形成一个消息向量，准备传递给中心节点。Combination Function：也称节点更新函数，作用是更新当前时刻的节点表示，组合当前时刻节点的表示以及从Aggregation Function中获得的消息。
(2)读出阶段：针对于图级别的任务（如图分类）仅仅获得节点级别的表示是不够的，需要通过读出函数（Readout Function）聚合节点级别的表示，计算获得图级别的表示。
因此，不同种类的GNN就是通过设计不同的Aggregation Function，Combination Function以及Readout Function实现的。也就是说，从邻居聚合的信息不同，邻居信息与自身信息的组合方式不同，或者节点的读出方式不同，最终都会导致我们最终获得的表示向量不同。不同的任务为了获得更准确的预测效果，会着重于抓取不同的信息。在PyG中，消息传递网络的通式为：
	x_i^k=γ^k (x_i^(k-1),⊕_(j∈N(i) ) ϕ^k (x_i^(k-1),x_j^(k-1),e_(j,i) ))	(28)
其中⊕γϕ表示可微的、排列不变的函数，如sum、mean或max，和表示可微的函数，如mlp(多层感知器)。
 
第3章  图变分自编码器模拟Ising模型
在第二章中，我们介绍了带边属性的图卷积网络模型和变分自编码器，下面我们将两者结合起来，构建图变分自编码器模型。与类似的图变分自编码器不同，我们将图变分自编码器用来重构节点属性，并忽略其边特征，学习节点属性的特征分布并将其重构。本章将介绍我们的格点图变分自编码器，以及生成模型的实验结果。
3.1 引言
Ising模型是物理学中最具代表性的模型之一，它可以用于描述许多物理系统的行为，包括磁性材料、玻璃转变、化学反应和生物学等。为了更好地理解和解释Ising模型在实际系统中的行为，生成不同条件下的Ising构型是一个重要的研究课题。传统的方法是使用蒙特卡罗模拟(Monte Carlo simulation)，但其计算复杂度高且不易实现高效的采样。近年来，机器学习的方法在解决这一问题上展现出了优异的表现。
在这个背景下，本文提出了一种新颖的图变分自编码器(VGAE)模型—格点图变分自编码器(GridVGAE)，用于生成不同条件下的Ising构型。与传统的VGAE不同，本文的模型将重点放在了节点的状态预测上，而不是边的预测，这也符合Ising模型中节点只有正负两个状态的特点。本文还采用了全连接神经网络来实现解码器，这样可以更好地对每一个节点进行特征提取，而不是聚合邻居信息。此外，本文采用了均方误差(MSE)和KL散度来作为损失函数，这样可以更好地平衡重建误差和潜在变量的KL散度，从而提高了生成质量。
通过实验结果的展示和分析，我们验证了本文提出的VGAE模型在生成不同条件下的Ising构型方面的有效性和优越性，同时也展示了本文方法在捕捉Ising模型中的关键特征方面的优越性。本文提出的模型为Ising模型的研究提供了一种新的思路和解决方法，同时也为其他相关领域的研究提供了借鉴。
3.2 数据预处理
首先我们随机生成一组二维矩阵，二维矩阵的值为1或-1，对二维矩阵进行Metropolis算法或者Wolff算法进行稳态模拟，之后使用PyG对Ising模型进行图结构处理，将数据文件以pkl文件的方式进行存储，同时计算稳态构型的能量与磁化强度，并将这些属性与构型以hdf5文件的形式进行存储，以便在模型生成后与模型生成的构型作对比。
3.3 格点图变分自编码器模型
传统的VGAE主要用于图数据的链接预测任务，即通过学习图结构中的节点信息和边信息，预测未观察到的边是否存在。VGAE的主要思路是使用编码器将节点嵌入向量空间，并且使用解码器对节点进行重构，从而预测边的存在性。在VGAE中，编码器通常使用图卷积网络将节点特征聚合到一个向量表示中，解码器同样也是用图卷积网络对节点特征进行重构。
而本文提出的VGAE则是将VAE的思想应用于图结构数据的一种方法。本文的VGAE主要是用于生成稳态下的Ising模型构型，目标是从潜在空间中采样生成新的Ising模型构型。VGAE的编码器部分将图中的节点嵌入到潜在空间中，解码器部分则将潜在空间的向量解码为节点的状态。在本文提出的VGAE中，编码器使用了图卷积网络将节点特征聚合到一个向量表示中，但解码器则使用全连接神经网络对每个节点进行独立的重构。所以我将该VGAE命名为格点图变分自编码器
相比较传统的VGAE模型，GridVGAE具有以下的特点与优势：
(1) VGAE模型的应用领域不同。本文提出的GridVGAE主要用于生成Ising模型构型，而传统VGAE主要用于链接预测任务。
(2) VGAE模型的解码器不同。传统VGAE的解码器通常使用图卷积网络对节点特征进行重构，而本文提出的GridVGAE则使用全连接神经网络对每个节点进行独立的重构。
(3) VGAE模型的性能不同。本文的GridVGAE已经在生成稳态下的Ising模型构型方面取得了很好的表现，证明了其在特定领域的有效性。
3.3.1 编码器
我们的编码器由三个卷积层构成，每个卷积层的通道数分别为32、32和64，激活函数为整流线性单元（ReLU）。为了规范化神经网络，我们采用了batchNorm、GraphNorm和0.5的dropout率。在图卷积的选择上，我们选择了H-GCN作为我们模型的图卷积网络，H-GCN能够将边权重纳入卷积聚合计算中，将节点和边的特征一起传递给下一层网络。H-GCN的卷积特性与Ising模型的特点十分吻合，所以本文选择H-GCN作为我们GridVGAE编码器的卷积层，H-GCN的卷积公式为：
	x_i^'=W_1 x_i+W_2 ∑_(j∈N(i))▒〖e_((j,i) )  ⋅x_j 〗	(1)


图3.1 H-GCN应用于Ising模型带边权重的示意图
Figure 3.1 Schematic diagram of H-GCN applied to the Ising model with edge weights
其中x_i表示节点特征，e_(j,i)表示从源节点j到目标节点i的边权重。
卷积操作中上层卷积的结果作为下层卷积的输入来进行卷积的堆叠：
	X ̂=GCN(GCN(X,A),A)	(2)
第三个卷积层我们采用两个不同的卷积网络来分别获取μ,logσ^2:
	μ=GCN_μ (X ̂,A)	(3)
	logσ^2=GCN_(logσ^2 ) (X ̂,A)	(4)
然后我们就可以从分布中进行采样z：
	z=μ+σ⊙ε,ε~N(0,1)	(5)
3.3.2 解码器
我们的采样结果z是节点的高维表示,在解码器部分,由于Ising模型的节点之间的连接方式是固定的,所以我们在解码器部分可以忽略Ising模型的边属性,对潜在变量z中的每个节点使用全连接神经网络(MLP),使其维度降维至1.此时我们可以将重构问题认为是对每个节点进行分类,使用sigmod激活函数,再将其按值进行分类,之后对所有节点进行重构就可以得到我们生成的Ising构型.
	(x_i ) ̅=MLP(z_i)	(6)
z_i代表节点的高维表示,通过全连接神经网络使其变为我们需要的重构节点.由于我们得到的结果为节点信息,实现的方式为对每个节点进行卷积和降维,这样做的好处不仅仅是可以处理不同节点数量的图而且避免了传统矩阵形式的卷积核提取特征所带来的噪音，我们的模型在适应各种尺寸的构型的同时精度也得到了保证。
我们可以进行合理的推测，不同尺寸的构型一起进行训练,可以让模型提取出不同尺寸下稳态构型的共性特征,从而使生成的构型更加符合真实构型。


图3-1 GridVGAE模型示意图;a1表示将构型预处理为图结构，a2表示将图进行图卷积操作，a3生成潜在变量，c代表的是三层卷积通道数，μ和σ代表潜在变量均值与方差，在解码器中，b1表示将μ和σ重整化为维度为64的节点，b2表示将节点通过全连接网络降维，b3表示节点重构为构型。
Figure 3-1 GridVGAE model schematic diagram; a1 represents the preprocessing of configuration into graph structure, a2 represents the graph into graph convolution operation, a3 generates latent variables, c represents the number of three-layer convolution channels, μ and σ represent the mean and variance of latent variables, in the decoder, b1 represents the renormalization of μ and σ into nodes with dimension 64, b2 represents the dimension reduction of nodes through the fully connected network. b3 denotes the reconstruction of nodes into configurations.

3.3.3 损失函数
损失函数我们采用均方误差(MSE)与KL散度相结合的方式来构造损失函数，我们将在附录中相信介绍这两种方法。
	L=MSE(X,X ̅ )+KL(q(Z|X,A)||p(Z))	(7)
均方误差(Mean Squared Error,MSE)是评估两个连续型随机变量预测结果误差的一种方法,通过用于评估回归模型的性能。它计算预测值和真实值之间差值的平方的平均值，可以用以下公式表示：
	MSE=∑_(i=1)^n▒(x_i- (x_i ) ̅ )^2 	(8)
其中n是样本数量，x_i是真实值,(x_i ) ̅是预测值。MSE越小表示预测结果越接近真实值，因此通过用作损失函数来优化回归模型的参数。
KL散度（Kullback-Leibler Divergence, KL散度）是一种用于衡量两个概率分布之间距离的指标。它的计算方式是衡量两个概率分布的相对熵（relative entropy），可以用以下公式表示：
	KL(P||Q)=∑_i▒〖p(i)  log⁡〖P(i)/Q(i) 〗 〗	(9)
其中P和Q是两个概率部分，i是概率分布中的元素。KL散度用于衡量P相对于Q的信息增益，因此通常用于优化生成模型的损失函数，使生成模型生成的样本分布尽可能接近真实样本的分布。
公式Eq.7这两项分别代表了重构误差和正则化项，均方误差可以用来衡量生成的节点状态和原始节点状态之间的重构误差，而KL散度可以用来惩罚生成的节点状态分布和隐变量分布之间的差异，从而使得生成的结果更加真实和多样化。这两个指标的结合可以兼顾数据重构和潜在空间的约束，帮助网络模型更好地学习到数据的分布结构，从而提高生成结果的质量和多样性。
具体来说，均方误差可以使网络更好地学习到输入数据的重要特征，从而提高重构图像的质量。而KL散度可以使网络更好地学习到数据的潜在分布结构，从而使生成的图像更加多样化，并且能够根据不同的条件生成不同的Ising构型。
此外，使用均方误差和KL散度还有一个好处是在模型训练过程中可以更好地平衡两者之间的权衡。因为均方误差和KL散度的值在量级上可能存在较大的差异，因此需要在训练过程中调整它们之间的权重比例，以便得到更好的结果。在实验过程中，因为节点的属性值会收到边的影响，并且边的影响是双向的，所以我们给KL散度一个1/8的权重，使其更好的得到结果，加权重与不加权重的实验效果会在下一小结进行对比。
3.3.4 生成器
生成器是一个由解码器部分组成的模型，我们通过在训练阶段对不同尺寸的构型放在一起进行训练，得到的是一个能够生成任意尺寸构型的生成器。在具体生成某种尺寸构型时，我们需要通过固定网络的生成节点数量来实现。这可以通过重复训练模型并在此过程中还试试尺寸固定技巧来实现。具体方案是我们可以在已训练完成的模型基础上，再进行1~5轮的尺寸固定训练，通过这种方式将网络中的生成节点数量转变为我们想要的构型节点数量，从而生成不同尺寸的构型。这种方法能够快速、有效地生成不同尺寸的构型，并且在保持模型性能的同时，使模型具有更好的适应性和泛化能力。
在生成过程中，我们并不需要再进行模型的训练，我们在训练完成后保存模型和训练出来的μ和σ，并用 生成器来生成我们想要的构型。


图3-3 生成器示意图；a1:将不同尺寸构型放入编码器中，a2:搭载不同的解码器,a3:不同的解码器生成不同尺寸的构型
Figure 3-3 Generator diagram; a1: Put different size configurations into the encoder, a2: carry different decoders,a3: different decoders generate different size configurations
3.4 实验结果与分析
3.4.1 实验设计
实验采用的数据集是由MCMC方法生成的稳态Ising构型和我们通过生成器生成的Ising构型。
实验的评估指标采用Ising模型的两个物理特性:平均能量与平均磁化强度，下面将介绍两种指标的公式：
	E=-(J∑_(<i,j>)▒σ_i  σ_j)/L^2 	(10)
其中J为常量，<i,j>表示只对最近邻原子求和，L表示Ising构型的尺寸，Eq.10代表了Ising构型的平均能量。
	M=(∑_i▒S_i )/L^2 	(11)
S_i表示每个晶格的磁化量，+1为1，-1为0，M便是平均磁化强度。
在实验的设计上，主要将实验分为三部分：第一部分主要分析模型的生成能力，将生成的构型与MCMC方法生成的构型进行物理特性上的比对，同时验证模型是否能生成不同尺寸的Ising构型；第二部分模型对比，将本文提出的模型与其他常用的生成模型进行比较，将模型所用的图卷积网络与其余图卷积网络相比较，从多个角度来评估模型的优劣性；第三部分敏感度分析，对模型超参数进行敏感度分析，例如KL散度权重，卷积操作的数量和类型等，以研究这些参数对模型性能的影响。
3.4.1 实验结果
由于图神经网络的特性，我们可以在一个生成网络模型中生成不同尺寸的Ising构型，在本小节，我们使用VGAE分别单独生成16，32尺寸的Ising构型，之后我们使用混合模型来生成16，32尺寸的Ising构型，观察生成的构型与MCMC方法生成的构型物理特性是否吻合。
从实验中，我们可以看出，在模型只需要生成单尺寸构型时，VGAE生成的构型与MCMC方法生成的构型近乎一致，在32与16尺寸共同训练的VGAE模型中，32尺寸的精度有所下降但依然符合Ising模型的物理特性，对16尺寸来将物理特性没有损失。所以VGAE在Ising模型的仿真模拟上具有重大意义，并且可以完成多尺寸构型的模拟生成且具有较高精度，同时在多尺寸的模拟中，较低尺寸的构型模拟不会有精度损失。
(a)
(b)

图3.4 (a)16尺寸下生成构型与真实构型能量分布差异图; (b)16尺寸下生成构型与真实构型磁化率分布差异图;
Figure. 3.4 (a) Energy distribution difference between the generated configuration and the real configuration at 16 dimensions; (b) Magnetic susceptibility distribution difference between the generated configuration and the real configuration at 16 dimensions;

(a)
(b)

图3.5 (a)32尺寸下生成构型与真实构型能量分布差异图; (b)32尺寸下生成构型与真实构型磁化率分布差异图;
Figure. 3.5 (a) Energy distribution difference between the generated configuration and the real configuration at 32 dimensions; (b) Magnetic susceptibility distribution difference between the generated configuration and the real configuration at 32 dimensions;
(a)
(b)

(c)
(d)

图3.6 在16和32混合尺寸生成下模型的性能;(a)(b)代表16尺寸的能量与磁化强度对比,(c)(d)代表32尺寸的能量与磁化强度对比
Figure 3.6 Model performance under 16 and 32 mixed size generation; (a)(b) represent the energy and magnetization contrast of size 16, and (c)(d) represent the energy and magnetization contrast of size 32

3.4.2  模型对比
在VGAE模型卷积层的选择当中，由于图神经网络的不断发展，我们有非常多的选择空间，例如基于谱的图卷积网络GCN，例如将注意力机制融合到图卷积当中的GAT，当然包括本实验所采用利用边权重的高维图卷积网络(H-GCN)，在本小节中，我们将三种不同的卷积操作分别进行实验模拟，观察使用不同模型生成的Ising构型与MCMC方法生成的Ising构型在物理表征上是否符合，以下便是实验结果：
(a)
(b)

图3.7 GCN,GAT,GirdVGAE模拟Ising模型与传统方法的物理特性分布比较
Figure 3.7 Comparison of the distribution of physical properties between the simulated Ising model of GCN,GAT,GirdVGAE and the traditional method
通过实验我们可以得知，使用GCN,GAT做卷积层并没有良好的效果，而使用H-GCN作为卷积层则具有较好的模拟效果。这得益于H-GCN采用的边属性，对于同样采用边特征的GAT来说，效果不如H-GCN的原因可能是因为多头注意力导致的过拟合问题无法解决，这只是一种猜测。
同样的，将三种卷积的重构准确性进行对比，我们还是可以发现使用H-GCN的VGAE拥有压倒性优势：
表3-1 图卷积重构准确率
Table 3-1 Figure convolution reconstruction accuracy
图卷积种类	重构准确率
H-GCN	99.99%
GCN	78.43%
GAT	73.45%
接下来，我们将VGAE与传统的生成网络在Ising模型上模拟做对比，参与实验的传统模型是VAE与GAN：
(a)
(b)

图3.8 不同神经网络模型生成Ising构型的准确率(a)表示构型的能量分布(b)表示构型的磁化强度分布
Figure 3.8 The accuracy of the Ising configuration generated by different neural network models (a) represents the energy distribution of the configuration (b) represents the magnetization distribution of the configuration
可以看出，VAE在模拟上的效果不太理想，而GAN的模拟效果与MCMC方法的物理特性基本符合，但是GAN网络由于传统卷积的限制，无法生成多尺寸的Ising构型，所以GridVGAE在精确率与GAN相近比VAE要高，并且GridVGAE相较于这两个模型拥有用于多尺寸的泛化性。
3.4.3 敏感度分析
本文中的模型拟合误差利于了KL散度的特性来收敛误差，KL散度的参数对模型的影响十分关键，本小节将KL散度的参数分别设置为1、1/4和1/16来进行实验分析：


图3.9 不同KL散度权重所带来的影响
Figure 3.9 The impact of different KL divergence weights
从实验结果中，我们可以看出，不同的KL散度权重对模型的准确性影响非常大。
3.5 分析与讨论
根据上一节的实验结果，我们可以对其进行分析与讨论，以此来总结出模型的优势与局限性，并将其转换在应用领域和做更好的改进。
在单尺寸模拟方面，生成出的16尺寸和32尺寸的构型物理特征与MCMC方法生成构型的物理特征基本吻合。这表明所提出的模型在生成单一尺寸的构型时具有较好的重构能力。同时，模型的生成结果也可以与传统的MCMC方法生成的构型进行比较，从而验证模型的有效性。
在多尺寸模拟方面，生成16尺寸的32尺寸的构型表现都不错，但32尺寸构型的表现略逊于单尺寸模型下的构型，16尺寸则要优于单尺寸模型。这可能是因为多种尺寸在一起训练时，模型的学习能力得到提升，由于数据集更加丰富，相应地训练出地模型泛化能力更好。对于32尺寸来说，由于要兼顾16尺寸的构型，所以准确性下降。所以在生成不同尺寸构型的时候，我们要采用不同的生成策略，以获得更好的生成效果。
在模型卷积对比方面，使用H-GCN的效果要好于使用GCN和GAT的效果。这可能是因为H-GCN可以更好地利用图结构中的局部信息和全局信息。相比之下，GCN和GAT更注重局部信息，忽略的全局信息。因此，在图结构中，具有较强的全局特征时，H-GCN能够更好地捕捉和利用这些信息，从而提高模型的性能。
在敏感度分析上，使用1/16的KL散度权重的损失值要好于使用1和1/4权重的KL散度权重。这表明较小的KL散度权重有利于构型的重构。在模型训练过程中，KL散度用于平衡重构误差和噪声项，较小的KL散度权重可以使模型更关注重构误差，从而提高重构准确度。
在卷积层数方面，3层卷积要好于多层卷积。这可能是因为多层卷积会引入更多的噪声和误差，从而降低了模型的重构能力。需要在模型训练时谨慎选择卷积层数，以获得更好的重构效果。
另外，从时间和计算资源的角度来看，我们的方法相对于传统的MCMC方法可以节省很多时间和计算资源。因为MCMC方法需要进行多次模拟和计算，而我们的方法只需要进行一次模型训练，之后便可以直接生成模拟结果。这对于大规模模拟和数据分析非常有帮助，可以提高工作效率和准确性。
综上所述，通过实验结果的分析与讨论，我们可以看出我们提出的方法在Ising模型的构型生成任务中取得了很好的效果，可以生成具有良好物理特性的构型，并且相对于传统的MCMC方法具有更高的效率和准确性。这种方法还可以扩展到其他复杂系统的模拟和分析中，具有很大的应用前景。
 
第4章  基于GridVGAE的物理模型生成应用系统
4.1 绪论
4.1.1 项目背景
物理模型是用来描述物质或现象的数学表达式或方程，它可以帮助我们理解和预测物理现象的规律和特性。以Ising模型为例，Ising模型可以用来研究相变、临界现象、磁化、熵等物理概念，也可以用来模拟复杂系统中的许多现象，如神经网络、生物进化、社会行为等。然而，物理模型的建立往往需要大量的实验数据和复杂的数学推导，这在很多情况下是困难或不可行的。因此，如何利用机器学习技术来自动生成或优化物理模型是一个具有重要意义和挑战性的研究课题。图神经网络是一种能够处理非欧几里得结构数据（如图、网格、点云等）的深度学习算法，它可以有效地提取图数据中的拓扑信息和特征信息，并且具有良好的泛化能力和可解释性。变分自编码器是一种基于变分推理的生成式模型，它可以从高维数据中学习潜在空间的分布，并且可以通过潜在变量来重构或生成新的数据样本。基于图神经网络和变分自编码器相结合的方法，在图像、文本、生物等领域已经展示了优异的生成性能。然而，在物理领域，这种方法还没有得到充分地应用和探索。
4.1.2 研发目的
本系统旨在开发一个基于web的应用系统，利用GridVGAE模型来模拟不同物理系统的构型和性质。GridVGAE是一种结合了图神经网络和变分自编码器的深度学习算法，能够从训练数据中自动学习潜在空间的分布，并重构潜在变量的分布。GridVGAE可以把高维的输入数据映射到潜在空间，从而可以更容易地检测隐藏的规律，发现更复杂的关系。GridVGAE还可以在不同尺寸的构型之间快速切换，提高模型的通用性和效率。与传统方法相比，本系统结合GridVGAE后具有以下优势：
	可以生成任意大小和形状的构型，不受网格结构或边界条件的限制；
	可以生成高质量和高精度的构型，与真实物理系统保持一致；
	可以提高计算效率和节省资源，减少冗余运算和存储空间。
本系统对于凝聚态物理学领域具有重要意义和价值，可以帮助研究人员更准确地预测物理性质，以及帮助设计出新材料和新模型，进而推动凝聚态物理理论的发展。
4.1.3 主要工作
本项目基于第三章所提出的基于图变分自编码器的Ising模型模拟器进行改进和扩展，形成可视化仿真系统，并完成以下工作：
(1) 设计并实现了一个基于Web技术（HTML/CSS/JavaScript） 的用户界面，方便用户输入参数并查看结果；
(2) 使用Python语言和PyTorch框架实现了后端服务器程序，并部署在云平台上；
(3) 使用Matplotlib库对生成结果进行可视化展示，并与传统方法进行对比验证；
对不同温度和外场条件下生成的Ising构型进行物理量（如能量、磁化率、比热等） 的计算，并与理论值进行对比分析；
4.2 开发技术及环境分析
本小节旨在介绍所用的开发技术及开发环境，以便能更加全面系统的了解开发过程中的思路与方法。
4.2.1 开发技术
编程语言：Python
Python 是一种高级的、解释型、面向对象的编程语言。它的语法简洁、易读易写，非常适合快速开发原型、科学计算、数据分析等领域。Python 支持多种编程范式，包括面向对象、函数式和过程式编程。它也有很强的社区支持，丰富的第三方库和框架可以帮助开发者快速实现各种应用。
后端框架：Flask
Flask 是一个轻量级的 Python Web 框架，它基于 Werkzeug WSGI 工具箱和 Jinja2 模板引擎。Flask 具有简单、灵活、可扩展的特点，使得它非常适合构建小型 Web 应用和 API 服务。Flask 的核心是通过路由定义处理不同的 HTTP 请求，同时它也提供了很多扩展，例如支持数据库、表单处理、用户认证等。
前端框架：Vue.js
Vue.js 是一个渐进式 JavaScript 前端框架，它专注于构建用户界面。Vue.js 采用了组件化开发的思想，将一个页面分解为多个组件，使得组件之间的耦合度降低，可维护性和可复用性增加。Vue.js 的 API 设计非常直观，易于学习和使用，同时它也提供了丰富的生态系统和插件，例如 Vuex 状态管理、Vue Router 路由管理等。 	数据库：MySQL
MySQL 是一种关系型数据库管理系统，它是最流行的开源数据库之一。MySQL 使用 SQL 语言进行查询和操作数据，支持多种数据类型、完整性约束和事务处理等。它也提供了高可用性、可扩展性和安全性等方面的解决方案，可以支持各种规模的应用场景。 	机器学习库：PyTorch
PyTorch 是一个基于 Python 的科学计算包，它主要用于深度学习应用。PyTorch 的特点是动态图，即在计算图的构建和执行过程中可以进行实时调整和优化，这使得它非常适合用于研究和实验开发。PyTorch 提供了各种深度学习模型和算法的实现，例如卷积神经网络、循环神经网络和变分自编码器等。同时，它也支持在 GPU 上进行并行计算，可以大幅度提高模型训练和推理的效率。
4.2.2 硬件环境
CPU：2*Xeon白金8180(56核2.5GHZ)
内存：512GB DDR4 2666
硬盘空间：2TB SSD + 150并行存储
显卡：10*QGP100(显存144GB)
带宽：9*PCIE 8x/每块显卡显存带宽716GBs
4.2.3 MVC开发模式
MVC(Model-View-Controller)是一种常用的软件架构模式。MVC模式将一个应用程序分为三个部分：模型、视图和控制器，每个部分都有自己的职责，相互之间又通过特定的规则联系起来，以实现应用程序的开发和维护。MVC模式的核心思想是将应用程序的数据、业务逻辑和用户界面分离开来，以实现更好的可维护性、可扩展性和可重用性。这种分离使得应用程序中的不同部分可以独立开发、测试和维护，也使得应用程序更容易适应不同的需求和变化。
模型（Model）：负责管理应用程序的数据和业务逻辑。模型是应用程序中的核心组件，通常包括数据存储、数据访问和数据处理等功能。
视图（View）：负责呈现模型的数据给用户，并处理用户的输入。视图是应用程序中用户界面的组成部分，通常包括各种UI控件、图形界面和文本界面等。
控制器（Controller）：负责协调模型和视图之间的交互，以及处理用户的输入。控制器是应用程序中的逻辑控制中心，通常包括业务逻辑、数据验证和用户交互等。


图4.1 MVC框架图
Figure 4.1 MVC framework
MVC模式的优点：
	分工明确，通过MVC模式可以把数据库的开发，程序业务逻辑开发以及页面开发分开，这样方便后期的代码维护也使得程序员之间分工更加明确。
	重用性高而模型具备可移植性，可以允许更换视图和控制器对象。这样可以为一个模型在运行的同时建立和使用多个视图，也可以使得所有关联的视图和控制器做到同步更新。
	提高了应用系统的可维护性、可扩展性、可移植性和组件的可复用性。因为不同部分之间的耦合度低，所以修改或增加某一部分不会影响其他部分。
MVC模式的缺点：
	没有明确的定义，不同人对MVC模式由不同理解和实现方式。这可能导致代码风格不统一或者难以理解
	降低了系统的性能以及增加了代码工作量。因为要在三个部分之间进行数据传递和转换，所以会消耗更多的资源和时间。
	增加了系统结构和实现过程的复杂度。因为要设计三个部分并保持它们之间协调一致，所以需要更多的技术和经验。
4.3 任务概述
4.3.1 任务描述
系统开发的目标是构建一个基于web的应用系统，本系统应用领域主要在物理与经济学领域通过生成不同模型来辅助研究物质特性或者社会性质，本系统能够实现以下功能：
	用户可以通过浏览器访问该应用系统，并进行注册，登陆，注销操作。
	提供简介、易用的用户界面，支持上传数据集，进行预处理、模型训练和预测。
	支持多种数据格式的导入和导出，包括CSV、Excel等。
	支持自定义数据预处理方式，例如数据清洗，特征提取等。
	支持自定义模型训练方法，包括训练参数、损失函数等。
	支持多种方式获取数据，包括传统方式与GridVGAE生成方式
	支持自定义卷积操作，既可以使用默认图卷积操作，也可以使用GCN,GAT等卷积操作，同样支持自己实现卷积。
(8) 系统实现不同模型的可视化表示，并允许用户自制可视化效果。
4.3.2 条件与约束
条件：
安全性：系统具有较强的安全性,对数据和相关信息具有较强的保护性； 
稳定性：系统应该有稳定的抗压能力在大多数情况下可以稳定运行；
兼容性：应与大多数硬件软件有良好的兼容性； 
可行性：系统应该有简单易懂的操作与明显的输入输出。
约束：
系统必须遵守相关的法规和版权协议；系统必须保证用户数据的安全性和隐私性；系统必须在规定的时间内完成开发和测试。
系统通过浏览器以网站的形式进行访问；服务器运行于Ubuntu linux操作系统。
4.3.3 用户特点
操作人员：操作人员是指使用本软件进行物理模型生成的用户，他们需要具备以下特点：
教育水平：操作人员应该具有本科以上的学历，并且有一定的物理学、数学和计算机科学的基础知识。
技术专长：能够使用本软件提供的用户界面和交互方式进行物理模型生成。
使用频度：操作人员可能会根据自己的研究目标和需求，不定期地使用本软件进行物理模型生成，但不会频繁地更换数据集或模型参数。
维护人员：维护人员是指负责本软件的更新、修复和优化的开发者，他们需要具备以下特点：
教育水平：维护人员应该具有硕士以上的学历，并且有深入的物理学、数学和计算机科学的专业知识。
技术专长：维护人员应该精通Python语言和Pytorch框架，并且能够使用本软件提供的源代码和文档进行物理模型生成算法的改进和扩展。
使用频度：维护人员可能会根据用户反馈或新技术发展，定期地对本软件进行更新、修复和优化，但不会大幅度地修改数据集或模型结构。
4.4 需求分析
4.4.1 功能需求
用户管理功能：系统应提供用户注册、登陆、注销等基本功能，以及用户信息修改、密码找回等辅助功能。
数据管理功能：系统应支持用户通过浏览器上传和下载数据集，并支持多种数据格式的导入和导出，包括CSV,Excel等。系统应支持自定义数据预处理方式，例如数据清洗，特征提取等。
模型管理功能：系统应支持用户自定义模型训练方法，包括训练参数、损失函数等。系统应支持多种方式获取数据，包括传统方式与GridVGAE生成方式。系统应支持自定义卷积操作，既可以使用默认图卷积操作，也可以使用GCN,GAT等卷积操作，同样支持自己实现卷积。
可视化功能：系统应实现不同模型的可视化表示，并允许用户自制可视化效果。
4.4.2 非功能需求
本系统应该满足以下性能、可靠性、安全性、可用性等方面的标准：
性能：系统应该能够在较短时间内完成一次构型生成任务，并且保证输出结果质量高。
可靠性：系统应该能够稳定地运行，在不同温度不同混合尺寸的参数下都能正常工作，并且处理异常情况（例如输入参数无效或超出范围）。
安全性：系统应该保护用户数据和隐私，不泄露或篡改用户输入或输出信息，并且防止恶意攻击或篡改。
可用性：系统应该提供友好和易用的用户界面，让用户可以方便地输入参数、查看输出结果和评估指标，并且提供必须的帮助和说明信息。
4.4.3 界面需求
本系统与用户和其他系统之间交互方式如下：
用户界面：本系统提供一个图形化界面，让用户可以通过鼠标或键盘输入温度，尺寸，模型类别等参数，并且通过屏幕查看输出结果和评估指标。界面设计简洁明了，符合人机交互原则。
硬件接口：本系统需要与计算机硬件进行交互，包括CPU、GPU、内存和硬盘等部件。硬件配置要求满足运行GridVGAE模型所需资源。
软件接口：本系统需要与操作系统、编程语言、开发框架等软件进行交互。软件环境要求支持运行GridVGAE模型所需求库和依赖项。
4.5 可行性分析
可行性分析是对系统在技术、经济、法律、社会等方面的可行性进行评估和分析，以确定是否值得投入资源和时间进行开发和实施。
4.5.1 技术可行性
本系统的技术难点主要在于GridVGAE模型的设计和实现，需要使用深度学习，图神经网络等先进技术。由第三章的实验结果可得，我们已经成功的开发了GridVGAE模型，并且在生成Ising模型构型仿麦呢取得了很好的表现。因此，本系统在技术上是可行的。
4.5.2 经济可行性
本系统的经济成本主要包括硬件设备，软件环境，人力资源等方面。硬件设备方面，需要一台配置较高的计算机来作为服务器部署，这需要一定的投资。软件环境方面，需要安装支持深度学习和图神经网络等库和依赖项的操作系统和编程语言，这需要一定的时间和精力。人力资源方面，需要有一定专业知识和技能的开发者来维护和优化GridVAE模型，这需要一定的培训和管理。本系统的经济收益包括提高物理模型的生成效率、质量、多样性等方面。这可能对物理学研究、教学等领域有着积极意义，并且有潜在市场需求。因此，本系统在经济上是可行的。
4.5.3 法律可行性
本系统涉及到用户数据和隐私保护、知识产权保护等法律问题。用户数据和隐私保护方面，需要遵守相关法律法规，并且获取用户同意后才能收集、存储、处理用户输入或输出信息，并且不泄露或篡改用户数据和隐私。知识产权保护方面，需要尊重原创作者对GridVGAE模型及其相关成果所享有的版权，并且不侵犯或滥用他人对类似或相关成果所享有的版权。因此，本系统在法律上是可行。
4.6 软件设计
4.6.1 总述
本系统是一个基于web的应用系统，为物理和经济学领域的研究人员提供辅助研究的工具。通过提供简洁易用的用户界面、支持数据的预处理、模型训练和预测、自定义数据预处理方式和模型训练方法、多种方式获取数据和自定义卷积操作等功能，让用户能够更加方便地进行研究工作。
4.6.2 总体设计
本系统主要分为四个模块，分别是用户管理模块，数据管理模块，模型管理模块，可视化模块。系统的总体结构与模块划分如图*所示。其中最主要的模块为模型管理模块，负责模型生成工作，其余模块都是辅助该模块。同时本系统会记录不同的模型种子，在下一次进行生成的时候，进行数据匹配。这样就会极大缩短模型生成时间，所有用户共享数据资源，极大的扩展了系统的可用性。


图4.2 系统总体框架图
Figure 4.2 Overall framework of the system
4.6.3 接口设计
接口设计是用来设计模块之间、模块与数据库之间的数据流向的设计，通过接口设计我们可以使功能更加明确，在本章中，我们共设计了用户登陆接口、数据集上传接口、数据集下载接口、模型生成接口、可视化转化接口、保存构型记录接口六大接口，覆盖所有模块的数据输入与输出，为软件编码打下良好基础。以下为各个接口的具体内容：
表4-1 用户登陆接口
Table 4-1 User login interface
接口名称	用户登录接口
接口描述	用户输入账号和密码来登陆系统
	字段名称	字段说明	说明	逻辑验证规则
请求参数	username:str	用户名	不可为空	1.为空时返回“用户名不可为空”
2.若无法在数据库检索到用户名，则返回“用户名或密码错误”
	password:str	密码	不可为空	1.为空时返回“密码名不可为空”
2.若无法在数据库检索到用户名，则返回“用户名或密码错误”
返回参数	code:int 状态码,0表示成功,其他表示失败
	message:str,状态信息
表4-2 数据集上传接口
Table 4-2 Data set upload interface
接口名称	数据集上传
接口描述	将数据集上传到系统中，以便用户可以使用它们进行模型训练和预测
	字段名称	字段说明	说明	逻辑验证规则
请求参数	user_id: int	用户ID	必须	必须是一个正整数，且存在于用户表中
	dataset_id:int	数据集ID	必须	必须是一个正整数
	dataset_name: str	数据集名称	必须	必须是一个非空字符串
	dataset_type: str	数据集类型	必须	必须是一个字符串，在以下列表中:[“Ising”,”XY”,”Heisenberg”,”Potts”,”Other”]
	dataset_data：list of list of float	数据集数据	必须	必须是一个非空的二位浮点数列表
	source: str	数据集来源	必须	必须是一个字符串，在以下列表中：[“generated”,”uploaded”]
返回参数	code:int 状态码,0表示成功,其他表示失败
	message:str,状态信息
表4-3 数据集下载接口
Table 4-3 Data set download interface
接口名称	数据集下载
接口描述	将数据集下载到本地计算机，以便用户可以使用它们进行模型训练和预测
	字段名称	字段说明	说明	逻辑验证规则
请求参数	user_id:int	用户ID	必须	1.为空时返回“文件名称不可为空”

	dataset_id:int	数据集ID	必须	1.为空时返回默认数据类型.dat
返回参数	code:int 状态码，0表示成功，其他表示失败
	message:str,状态信息
	dataset_data:list of list of float，数据集数据
表4-4 模型生成接口
Table 4-4 Model generation interface
接口名称	模型生成
接口描述	将用户上传或者后端数据加载然后用GridVGAE生成构型
	字段名称与类型	字段说明	说明	示例	逻辑验证规则
请求参数	user_id:int	用户ID	不可为空	syh	1. 必须是一个整数,且存在于用户表中
	data_id:int	数据集ID	不可为空	Ising_001	1.必须是一个正整数,且存在于数据表中,且属于当前用户或者是公开数据
	model_id:int	模型ID	不可为空	GridVGAE	1.必须是一个正整数,且属于当前用户或者是公开模型
	config:dict	配置信息	JSON格式	{“loss”:…}	1.必须是一个合法的JSON格式的字典，且包含必要的模型配置参数，例如卷积类型，损失函数等
返回参数	code:int 状态码,0表示成功,其他表示失败
	message:str,状态信息
	data:dict,返回数据
generated_data:list of list of float 生成新的构型数据
表4-5 可视化转化接口
Table 4-5 Visual transformation interface
接口名称	可视化转换
接口描述	将神经网络生成的模型用图表的方式可视化
	字段名称与类型	字段说明	说明	示例	逻辑验证规则
请求参数	user_id:int	用户ID	不可为空	syh	必须是一个整数,且存在于用户表中

	data_id:int	数据集ID	不可为空	Ising_001	必须是一个正整数,且存在于数据表中,且属于当前用户或者是公开数据
	model_id:int	模型ID	不可为空	GridVGAE	必须是一个正整数,且属于当前用户或者是公开模型
	chart_type:str	图表类型	可选,默认为散点图	line	必须是一个字符串，在以下列表中：[“scatter”, “line”, “bar”, “pie”, “surface”, “heatmap”]
返回参数	code:int 状态码,0表示成功,其他表示失败
	message:str,状态信息
	data:dict,返回数据：
	x:list of float,x轴数据
	y:list of float,y轴数据
	z:list of float or None,z轴数据(如果是三维表)
	lable:list of str or None,标签数据(如果有分类信息)
表4-6 保存构型记录接口
Table 4-6 holds the configuration record interface
接口名称	保存构型记录
接口描述	将用户生成或者上传的构型信息和记录保存到数据库中
	字段名称与类型	字段说明	说明	逻辑验证规则
请求参数	user_id:int	用户ID	不可为空	必须是一个整数,且存在于用户表中
	config_id:int	模型ID	不可为空	必须是一个正整数,且属于当前用户或者是公开模型
	config_name:str	模型名称	不可为空	必须是一个非空字符串
				
(续表)
	config_type:str	模型类型	不可为空	[“Ising”,”XY”,”Heisenberg”,”Potts”,”Other”]，在以上列表中
	config_status:int	模型状态	不可为空	必须是一个整数，在以下列表中
	config_data:list of list of float	模型数据	不可为空	必须是一个非空的二维浮点数列表
	source:str	模型来源	不可为空	必须是一个字符串，在以下列表中:[“generated”,”uploaded”]
返回参数	code:int 状态码,0表示成功,其他表示失败
	message:str,状态信息
4.6.4 模块设计
用户管理模块：
用户管理模块主要负责用户的登陆，注册，注销操作，在用户没有注册之前将只能停留在登录界面，只有用户完成注册并登陆后，用户才能进入系统主界面。图4.2展示了用户管理模块的运行流程，用户管理模块的作用主要是为系统安全考虑，只有本站用户才能使用系统功能，并且系统会将用户的历史信息以及生成偏好进行保存，与模型管理模块结合，更好的服务用户。


图4.2 用户管理模块
Figure 4.2 User management module
数据管理模块：
数据管理作为系统的上下游，负责用户数据的上传与系统数据的下载，作为系统的承上启下模块，扮演者非常重要的角色，数据管理模块作为系统的基石，没有数据管理模块，系统就无法正常的运行。它的主要功能流程如图4.3所示：


图4.3 数据管理模块
Figure 4.3 Data management module
模型管理模块：
模型管理模块内核搭载了我们的GridVGAE算法，用来将从数据管理模块预处理的数据在数据管理模块运行，在生成模型前，我们需要选定参数，用户可以使用已经成熟的参数或者使用自己个性化的参数来进行科研创新，在模型管理模块，我们支持用户自定义卷积操作或者使用成熟的图卷积，同时可以选择损失函数的选择、KL权重大小以及卷积层数。当然我们也会提供成熟方案以方便量产。图*代表模型管理模块的功能流程：


图4.4模型管理模块
 Figure 4.4 Model management module
可视化模块：
可视化模块作为系统的展示接口，可以使用户直观的了解模型生成的好坏，以及生成构型的物理特性以及样貌。在可视化模块中，我们集成了最主要的模型可视化方法，同样可以使用户自定义可视化样式，使用户有更多的选择。


图4.5 可视化模块
Figure 4.5 Visualization module
4.6.5 容灾设计
本项目可能出现的出错情况包括：
	用户输入错误或非法数据导致程序异常或崩溃
	网络故障或攻击导致数据传输中断或丢失
	服务器故障或损坏导致数据无法访问或处理
	数据库故障或损坏导致数据丢失或损毁
	火灾、水灾、地震等自然灾害导致硬件设备损坏或无法使用
为了应对可能出现的出错情况，本项目采用以下容灾系统技术方案：
	对用户输入进行合法性检查和异常处理，防止程序异常或崩溃
	使用加密和认证技术保护网络传输的安全性，使用重传和校验技术保证网络传输的可靠性
	使用负载均衡和集群技术提高服务器的可用性，使用监控和报警技术及时发现服务器的故障
	使用备份和恢复技术保护数据库的完整性，使用分区和复制技术提高数据库的性能
	使用防火、防水、防震等措施保护硬件设备的安全性，使用电源切换和发电机等设备保证硬件设备的稳定性
为了保证容灾系统的正常运行和有效维护，本项目采用以下容灾系统运行维护方案：
	定期对用户输入进行测试和评估，优化程序异常处理逻辑和提示信息
	定期对网络传输进行测试和评估，优化网络加密认证算法和重传校验机制
	定期对服务器进行测试和评估，优化负载均衡策略和集群配置参数
	定期对数据库进行测试和评估，优化备份恢复策略和分区复制规则
	定期对硬件设备进行测试和评估，优化防火防水防震措施和电源切换发电机设备
4.6.7 其他设计
安全性设计：数据库加密：对于敏感数据，采用加密方式存储，保证数据安全；权限控制：对于不同的用户，采用不同的权限控制，保证数据的安全性；防止SQL注入：采用参数化查询的方式，防止SQL注入攻击；防止XSS攻击：采用输入过滤的方式，防止XSS攻击；防止CSRF攻击：采用Token验证的方式，防止CSRF攻击。
可靠性设计：数据备份：对于重要的数据，采用定期备份的方式，保证数据的可靠性；异常处理：对于系统中的异常，采用日志记录的方式，方便后期排查问题；代码规范：采用代码规范的方式，保证代码的可读性和可维护性；单元测试：采用单元测试的方式，保证代码的正确性和可靠性。
效率设计：缓存优化：采用缓存的方式，减少数据库的访问次数，提高系统的效率；据库优化：对于数据库的查询，采用索引的方式，提高查询效率；码优化：采用代码优化的方式，减少代码的执行时间，提高系统的效率。 
